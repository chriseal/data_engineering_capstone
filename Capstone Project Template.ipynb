{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Understanding US Immigration\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "This project processes raw US immigration data into a analytics-ready data warehouse, supported by city and airport dimensions. Spark is used to process large volumes of data, and S3 is used for storage to provide visibility into the pipeline and results.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import utils as uz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data & Step 2: Explore and Assess the Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport Data Overview\n",
    "\n",
    "- This is a simple table of airport codes and corresponding cities. It comes from here: https://datahub.io/core/airport-codes#data. \n",
    "- About 55k airports represented from around the world\n",
    "- `coordinates` are a string representation of latitude and longitude\n",
    "- Few missing values / pretty good data quality, other than the `_code` columns and `elevation_ft`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting: raw - airport\n",
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n",
      "Shape: (55075, 12)\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Null counts:\n",
      "+-----+----+----+------------+---------+-----------+----------+------------+--------+---------+----------+-----------+\n",
      "|ident|type|name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|coordinates|\n",
      "+-----+----+----+------------+---------+-----------+----------+------------+--------+---------+----------+-----------+\n",
      "|    0|   0|   0|        7006|        0|          0|         0|        5676|   14045|    45886|     26389|          0|\n",
      "+-----+----+----+------------+---------+-----------+----------+------------+--------+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in the airport data\n",
    "io = uz.S3IO('airport', 'raw')\n",
    "airport_raw = io.get()\n",
    "uz.df_overview(airport_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Airport Data Exploratory Analysis\n",
    "\n",
    "- Airport `type` is the type of airport category, most being `small_airport` and some `closed` / inactive\n",
    "- All continents are covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "+--------------+-----+\n",
      "|          type|count|\n",
      "+--------------+-----+\n",
      "| small_airport|33965|\n",
      "|      heliport|11287|\n",
      "|medium_airport| 4550|\n",
      "|        closed| 3606|\n",
      "| seaplane_base| 1016|\n",
      "| large_airport|  627|\n",
      "|   balloonport|   24|\n",
      "+--------------+-----+\n",
      "\n",
      "continent\n",
      "+---------+-----+\n",
      "|continent|count|\n",
      "+---------+-----+\n",
      "|       NA|27719|\n",
      "|       EU| 7840|\n",
      "|       SA| 7709|\n",
      "|       AS| 5350|\n",
      "|       AF| 3362|\n",
      "|       OC| 3067|\n",
      "|       AN|   28|\n",
      "+---------+-----+\n",
      "\n",
      "iso_country\n",
      "+-----------+-----+\n",
      "|iso_country|count|\n",
      "+-----------+-----+\n",
      "|         US|22757|\n",
      "|         BR| 4334|\n",
      "|         CA| 2784|\n",
      "|         AU| 1963|\n",
      "|         KR| 1376|\n",
      "|         MX| 1181|\n",
      "|         RU| 1040|\n",
      "|         DE|  947|\n",
      "|         GB|  911|\n",
      "|         FR|  850|\n",
      "|         AR|  848|\n",
      "|         CO|  706|\n",
      "|         IT|  671|\n",
      "|         PG|  593|\n",
      "|         VE|  592|\n",
      "|         ZA|  489|\n",
      "|         CL|  474|\n",
      "|         ID|  470|\n",
      "|         ES|  416|\n",
      "|         CN|  404|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|      elevation_ft|\n",
      "+-------+------------------+\n",
      "|  count|             48069|\n",
      "|   mean|1240.7896773388254|\n",
      "| stddev|1602.3634593484142|\n",
      "|    min|             -1266|\n",
      "|    max|             22000|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uz.value_counts(airport_raw, 'type')\n",
    "uz.value_counts(airport_raw, 'continent')\n",
    "uz.value_counts(airport_raw, 'iso_country')\n",
    "airport_raw.describe(['elevation_ft']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### City Data Overview\n",
    "\n",
    "- U.S. City Demographic Data: This data comes from OpenSoft. You can read more about it here: https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/.\n",
    "- About 3K US cities with very few missing data points\n",
    "- A snapshot of demographics data, last modified in 2018\n",
    "- Some columns are being read in as continuous numbers, rather than integers\n",
    "- Unsure what `Count` means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting: raw - city\n",
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n",
      "Shape: (2891, 12)\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Null counts:\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|City|State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|Race|Count|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|   0|    0|         0|              3|                3|               0|                13|          13|                    16|         0|   0|    0|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "io = uz.S3IO('city', 'raw')\n",
    "city_raw = io.get()\n",
    "uz.df_overview(city_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### City Data Exploratory Analysis\n",
    "\n",
    "- Rows are repeated for each different race. This could be improved upon.\n",
    "- There appear to be 5 different races represented (not too many to put in separate columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|         City|   State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+-------------+--------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|Silver Spring|Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|Silver Spring|Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|               White|37756|\n",
      "|Silver Spring|Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|Black or African-...|21330|\n",
      "|Silver Spring|Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|American Indian a...| 1084|\n",
      "|Silver Spring|Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|               Asian| 8841|\n",
      "+-------------+--------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_raw.where(uz.F.col(\"City\") == \"Silver Spring\").where(uz.F.col(\"City\") == \"Silver Spring\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State\n",
      "+--------------+-----+\n",
      "|         State|count|\n",
      "+--------------+-----+\n",
      "|    California|  676|\n",
      "|         Texas|  273|\n",
      "|       Florida|  222|\n",
      "|      Illinois|   91|\n",
      "|    Washington|   85|\n",
      "|       Arizona|   80|\n",
      "|      Colorado|   80|\n",
      "|      Michigan|   79|\n",
      "|North Carolina|   70|\n",
      "|      Virginia|   70|\n",
      "| Massachusetts|   69|\n",
      "|    New Jersey|   57|\n",
      "|       Georgia|   55|\n",
      "|     Minnesota|   54|\n",
      "|      New York|   54|\n",
      "|       Indiana|   51|\n",
      "|      Maryland|   50|\n",
      "|          Ohio|   49|\n",
      "|          Utah|   48|\n",
      "|     Wisconsin|   45|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Race\n",
      "+--------------------+-----+\n",
      "|                Race|count|\n",
      "+--------------------+-----+\n",
      "|  Hispanic or Latino|  596|\n",
      "|               White|  589|\n",
      "|Black or African-...|  584|\n",
      "|               Asian|  583|\n",
      "|American Indian a...|  539|\n",
      "+--------------------+-----+\n",
      "\n",
      "+-------+-----------------+----------------------+\n",
      "|summary|       Median Age|Average Household Size|\n",
      "+-------+-----------------+----------------------+\n",
      "|  count|             2891|                  2875|\n",
      "|   mean|35.49488066413016|     2.742542608695655|\n",
      "| stddev|4.401616730099886|    0.4332910878973046|\n",
      "|    min|             22.9|                   2.0|\n",
      "|    max|             70.5|                  4.98|\n",
      "+-------+-----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uz.value_counts(city_raw, 'State')\n",
    "uz.value_counts(city_raw, 'Race')\n",
    "city_raw.describe(['Median Age', 'Average Household Size']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### SAS Data Overview\n",
    "\n",
    "- date columns are being read in as floats\n",
    "- lots of data that isn't human readable / needs to be mapped\n",
    "- also, some text-based columns could be mapped in a transform step for storage optimization\n",
    "- columns need to be renamed for readability\n",
    "- `I94PORT`, `I94CIT`, `I94RES` need cleaning to derive city|state|country info as relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting: raw - sas\n",
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n",
      "Shape: (3096313, 28)\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|\n",
      "|5748520.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     F|  null|     DL|9.495645143E10|00040|      B1|\n",
      "|5748521.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  28.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1988.0|10292016|     M|  null|     DL|9.495638813E10|00040|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Null counts:\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|  occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender| insnum|airline|admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|    0|    0|     0|     0|     0|      0|      0|    239| 152592| 142457|   802|      0|    0|       1| 1881250|3088187|    238| 138429|3095921| 138429|    802|    477|414269|2982605|  83627|     0|19549|       0|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "io = uz.S3IO('sas', 'raw')\n",
    "sas_raw = io.get()\n",
    "uz.df_overview(sas_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### SAS Data Exploratory Analysis\n",
    "\n",
    "- Looks like all data is from April of 2016\n",
    "- pretty evenly-spread birth years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "| i94yr|i94mon|\n",
      "+------+------+\n",
      "|2016.0|   4.0|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sas_raw.select('i94yr','i94mon').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "+------+-------+\n",
      "|gender|  count|\n",
      "+------+-------+\n",
      "|     M|1377224|\n",
      "|     F|1302743|\n",
      "|  null| 414269|\n",
      "|     X|   1610|\n",
      "|     U|    467|\n",
      "+------+-------+\n",
      "\n",
      "matflag\n",
      "+-------+-------+\n",
      "|matflag|  count|\n",
      "+-------+-------+\n",
      "|      M|2957884|\n",
      "|   null| 138429|\n",
      "+-------+-------+\n",
      "\n",
      "biryear\n",
      "+-------+-----+\n",
      "|biryear|count|\n",
      "+-------+-----+\n",
      "| 1986.0|71958|\n",
      "| 1983.0|70415|\n",
      "| 1985.0|70409|\n",
      "| 1982.0|70251|\n",
      "| 1984.0|69809|\n",
      "| 1981.0|69626|\n",
      "| 1980.0|67960|\n",
      "| 1987.0|67762|\n",
      "| 1976.0|66568|\n",
      "| 1979.0|66494|\n",
      "| 1988.0|65566|\n",
      "| 1978.0|64262|\n",
      "| 1977.0|63035|\n",
      "| 1975.0|62622|\n",
      "| 1974.0|62150|\n",
      "| 1971.0|62075|\n",
      "| 1972.0|62001|\n",
      "| 1973.0|61430|\n",
      "| 1989.0|60340|\n",
      "| 1970.0|59730|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uz.value_counts(sas_raw, 'gender')\n",
    "uz.value_counts(sas_raw, 'matflag')\n",
    "uz.value_counts(sas_raw, 'biryear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting: staging - sas\n",
      "Earliest date available in SAS data: 2016-04-01\n"
     ]
    }
   ],
   "source": [
    "io = uz.S3IO('sas', 'staging')\n",
    "min_date = io.get().agg({\"arrdate\": \"min\"}).collect()[0]['min(arrdate)']\n",
    "print(f\"Earliest date available in SAS data: {min_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Weather Data Overview\n",
    "\n",
    "- This dataset contains temperature information from around the world in various groupings - city, state, etc.\n",
    "- As you can see from the analysis section, the _dates don't overlap with the SAS data, and thus, we cannot use this dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: date (nullable = true)\n",
      " |-- LandAverageTemperature: double (nullable = true)\n",
      " |-- LandAverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandMaxTemperature: double (nullable = true)\n",
      " |-- LandMaxTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandMinTemperature: double (nullable = true)\n",
      " |-- LandMinTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandAndOceanAverageTemperature: double (nullable = true)\n",
      " |-- LandAndOceanAverageTemperatureUncertainty: double (nullable = true)\n",
      "\n",
      "Shape: (3180, 9)\n",
      "+----------+----------------------+---------------------------------+------------------+-----------------------------+------------------+-----------------------------+------------------------------+-----------------------------------------+\n",
      "|        dt|LandAverageTemperature|LandAverageTemperatureUncertainty|LandMaxTemperature|LandMaxTemperatureUncertainty|LandMinTemperature|LandMinTemperatureUncertainty|LandAndOceanAverageTemperature|LandAndOceanAverageTemperatureUncertainty|\n",
      "+----------+----------------------+---------------------------------+------------------+-----------------------------+------------------+-----------------------------+------------------------------+-----------------------------------------+\n",
      "|1750-01-01|    3.0340000000000003|                            3.574|              null|                         null|              null|                         null|                          null|                                     null|\n",
      "|1750-02-01|                 3.083|                            3.702|              null|                         null|              null|                         null|                          null|                                     null|\n",
      "|1750-03-01|                 5.626|                            3.076|              null|                         null|              null|                         null|                          null|                                     null|\n",
      "|1750-04-01|                  8.49|                            2.451|              null|                         null|              null|                         null|                          null|                                     null|\n",
      "|1750-05-01|                11.573|                            2.072|              null|                         null|              null|                         null|                          null|                                     null|\n",
      "+----------+----------------------+---------------------------------+------------------+-----------------------------+------------------+-----------------------------+------------------------------+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Null counts:\n",
      "+---+----------------------+---------------------------------+------------------+-----------------------------+------------------+-----------------------------+------------------------------+-----------------------------------------+\n",
      "| dt|LandAverageTemperature|LandAverageTemperatureUncertainty|LandMaxTemperature|LandMaxTemperatureUncertainty|LandMinTemperature|LandMinTemperatureUncertainty|LandAndOceanAverageTemperature|LandAndOceanAverageTemperatureUncertainty|\n",
      "+---+----------------------+---------------------------------+------------------+-----------------------------+------------------+-----------------------------+------------------------------+-----------------------------------------+\n",
      "|  0|                     0|                                0|              1188|                         1188|              1188|                         1188|                          1188|                                     1188|\n",
      "+---+----------------------+---------------------------------+------------------+-----------------------------+------------------+-----------------------------+------------------------------+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "io = uz.S3IO('GlobalTemperatures', 'raw') # for debugging\n",
    "weather = io.get().where(uz.F.col(\"LandAverageTemperature\").isNotNull())\n",
    "uz.df_overview(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Weather Data Exploratory Analysis\n",
    "\n",
    "- The maximum date represented in the weather dataset(s) is 12/1/2015 and the minimum date represented in the SAS dataset is 4/1/2016\n",
    "- Therefore, it would be fruitless to join weather data to this data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting: raw - globaltemperatures\n"
     ]
    }
   ],
   "source": [
    "weather = weather.withColumn(\"dt\", uz.F.col('dt').cast(\"date\"))\n",
    "min_date = uz.datetime.date(2016, 4, 1) # from previous SAS cell\n",
    "assert weather.groupby('dt').count().agg({'count': 'max'}).collect()[0]['max(count)'] == 1, \"Possible duplicate dates. Should have 1 row per date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data range for GlobalTemperatures is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(max(dt)=datetime.date(2015, 12, 1))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The data range for GlobalTemperatures is:\")\n",
    "weather.agg({\"dt\": \"max\"}).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- As you can see, no weather datasets overlap dates with the SAS data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting: raw - globallandtemperaturesbycity\n",
      "GlobalLandTemperaturesByCity max available date: 2013-09-01 00:00:00\n",
      "Getting: raw - globallandtemperaturesbymajorcity\n",
      "GlobalLandTemperaturesByMajorCity max available date: 2013-09-01 00:00:00\n",
      "Getting: raw - globallandtemperaturesbycountry\n",
      "GlobalLandTemperaturesByCountry max available date: 2013-09-01 00:00:00\n",
      "Getting: raw - globallandtemperaturesbystate\n",
      "GlobalLandTemperaturesByState max available date: 2013-09-01 00:00:00\n",
      "Getting: raw - globaltemperatures\n",
      "GlobalTemperatures max available date: 2015-12-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "for key in ['GlobalLandTemperaturesByCity', 'GlobalLandTemperaturesByMajorCity','GlobalLandTemperaturesByCountry','GlobalLandTemperaturesByState','GlobalTemperatures']:\n",
    "    io = uz.S3IO(key,'raw' )\n",
    "    df = io.get()\n",
    "    if key == 'GlobalTemperatures':\n",
    "        df = df.where(uz.F.col(\"LandAverageTemperature\").isNotNull())\n",
    "    else:\n",
    "        df = df.where(uz.F.col(\"AverageTemperature\").isNotNull())\\\n",
    "            .filter(\"Country = 'United States'\")\n",
    "    res = df.agg({\"dt\": \"max\"}).collect()[0]['max(dt)']\n",
    "    print(key, 'max available date:', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save raw files to S3 bucket\n",
    "# NOTE: this was done in a console outside the purview of this notebook\n",
    "uz.load_raw_files_to_s3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Airport Cleaning Steps\n",
    "\n",
    "###### Airport To Staging\n",
    "\n",
    "- separate `latitude` and `longitude` columns, and cast as doubles\n",
    "- strip text fields - `iso_region`, `municipality`\n",
    "- filter to USA only\n",
    "- derive `state` field from iso_region\n",
    "\n",
    "###### Airport To Warehouse\n",
    "\n",
    "- append additional cities from `airport` to `city`\n",
    "- add `city_id` from city to airport\n",
    "- create `id` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Cities Cleaning Steps\n",
    "\n",
    "###### Cities to Staging\n",
    "\n",
    "- rename various columns\n",
    "- select distinct rows, ignoring race\n",
    "- append race column counts for each race, respectively\n",
    "\n",
    "###### Cities to Warehouse\n",
    "\n",
    "- append additional locations from `sas` and `airport` tables\n",
    "- create `id` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### SAS Cleaning Steps\n",
    "\n",
    "###### SAS to Staging\n",
    "\n",
    "- rename various columns\n",
    "    `I94YR` to `year`\n",
    "    `I94MON` to `month`\n",
    "    `I94CIT` to `I94CIT`\n",
    "    `I94RES` to `I94RES`\n",
    "    `I94PORT` to `port`\n",
    "    `ARRDATE` to `arrdate`\n",
    "    `I94MODE` to `arrmode`\n",
    "    `I94ADDR` to `addr_state`\n",
    "    `DEPDATE` to `depdate`\n",
    "    `I94BIR` to `age`\n",
    "    `I94VISA` to `visa`\n",
    "    `MATFLAG` to `match_flag`\n",
    "    `BIRYEAR` to `birth_year`\n",
    "    `GENDER` to `gender`\n",
    "    `AIRLINE` to `airline`\n",
    "    `I94YR` to `year`\n",
    "    `admnum` to `admission_num`\n",
    "    `FLTNO` to `flight_num`\n",
    "- cast columns read in as floats into integers (`birth_year`, `year`, `month`, `age`, `arrmode`, `I94CIT`, `I94RES`, `arrdate`, `depdate`, `visa`, `cicid`)\n",
    "- Apply full-text maps from dataset to create `*_id` columns and drop the full-text columns for reduced storage requirements and save to `SAS_ID_TO_FULLTEXT_MAPS_FPATH`\n",
    "- convert `match_flag` to boolean\n",
    "- convert `arrdate` and `depdate` to `Date` type\n",
    "\n",
    "###### SAS to Warehouse\n",
    "\n",
    "- append additional locations to `city` table\n",
    "- add `city_id` column\n",
    "- add `id` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "- Normalize SAS dataset because it is the fact table in this scenario, which saves storage space and enhances performance\n",
    "- Consider the `airport` and `city` tables as dimensions\n",
    "- Apply mapping on read from data warehouse for human-readable filtering for mostly `sas`, but also, some for `airport`\n",
    "- User can quickly merge datasets with `city_id` column\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "- Save raw files to S3 bucket\n",
    "- Transform `sas`, `airport`, `city` to staging (store in S3 or transform on the fly)\n",
    "- Transform `sas`, `airport`, `city` to warehouse (store in S3 or transform on the fly)\n",
    "- Apply various mappings upon read from warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Transform the datasets TO warehouse\n",
    "\n",
    "- Transforms the data from staging to storage in the data warehouse\n",
    "- Data is cleaned and formatted to be what it will look like when it is stored in the data warehouse\n",
    "- Because I was having internet speed issues (probably due to COV19), this data was not stored in the requisite S3 bucket, and instead is displayed here for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing all datasets for storage in the data warehouse\n",
      "Transforming city to staging as an intermediary step\n",
      "Loading raw city file from Udacity workspace\n",
      "Getting: raw - city\n",
      "Transforming airport to staging as an intermediary step\n",
      "Getting: raw - airport\n",
      "Transforming sas to staging as an intermediary step\n",
      "Getting: raw - sas\n",
      "Creating id columns from full-text columns for faster querying...\n",
      "...creating visatype_id to visatype mapping\n",
      "...creating airline_id to airline mapping\n",
      "...creating gender_id to gender mapping\n",
      "Creating city_id columns...\n",
      "...get cities not represented in cities dimension from SAS and append to city table\n",
      "......sas_unique_locations shape: (280, 2)\n",
      "......Additional locations from SAS: 205\n",
      "\tcity table shape: (801, 15)\n",
      "...get cities not represented in cities dimension from AIRPORT and append to city table\n",
      "......airport_unique_locations shape: (11951, 2)\n",
      "......Additional locations from AIRPORT: 11388\n",
      "\tcity table shape: (12189, 15)\n",
      "Add monotonically increasing city ID to city table\n",
      "Apply city_id to airport\n",
      "Apply city_id to sas\n",
      "city to warehouse\n",
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_full: string (nullable = true)\n",
      " |-- median_age: double (nullable = true)\n",
      " |-- male_pop: integer (nullable = true)\n",
      " |-- female_pop: integer (nullable = true)\n",
      " |-- total_pop: integer (nullable = true)\n",
      " |-- num_veterans: integer (nullable = true)\n",
      " |-- foreign_born: integer (nullable = true)\n",
      " |-- avg_household_size: double (nullable = true)\n",
      " |-- Black or African-American: integer (nullable = true)\n",
      " |-- Hispanic or Latino: integer (nullable = true)\n",
      " |-- White: integer (nullable = true)\n",
      " |-- Asian: integer (nullable = true)\n",
      " |-- American Indian and Alaska Native: integer (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n",
      "Shape: (12189, 16)\n",
      "+-----------+-----+--------------+----------+--------+----------+---------+------------+------------+------------------+-------------------------+------------------+------+-----+---------------------------------+---+\n",
      "|       city|state|    state_full|median_age|male_pop|female_pop|total_pop|num_veterans|foreign_born|avg_household_size|Black or African-American|Hispanic or Latino| White|Asian|American Indian and Alaska Native| id|\n",
      "+-----------+-----+--------------+----------+--------+----------+---------+------------+------------+------------------+-------------------------+------------------+------+-----+---------------------------------+---+\n",
      "|   Gastonia|   NC|North Carolina|      36.9|   35527|     39023|    74550|        3537|        5715|              2.67|                    22179|              6653| 46362| 2788|                              603|  0|\n",
      "|  Henderson|   NV|        Nevada|      42.5|  139412|    146246|   285658|       25045|       35666|              2.55|                    18816|             47154|234301|24931|                             3036|  1|\n",
      "|Yorba Linda|   CA|    California|      45.5|   31960|     36006|    67966|        3171|       15532|               3.0|                     1326|             10599| 49980|17616|                              211|  2|\n",
      "|    Medford|   OR|        Oregon|      38.6|   39606|     40189|    79795|        6632|        6185|              2.65|                     1201|             14294| 75464| 2135|                             1239|  3|\n",
      "|      Kenai|   AK|          null|      null|    null|      null|     null|        null|        null|              null|                     null|              null|  null| null|                             null|  4|\n",
      "+-----------+-----+--------------+----------+--------+----------+---------+------------+------------+------------------+-------------------------+------------------+------+-----+---------------------------------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "Null counts:\n",
      "+----+-----+----------+----------+--------+----------+---------+------------+------------+------------------+-------------------------+------------------+-----+-----+---------------------------------+---+\n",
      "|city|state|state_full|median_age|male_pop|female_pop|total_pop|num_veterans|foreign_born|avg_household_size|Black or African-American|Hispanic or Latino|White|Asian|American Indian and Alaska Native| id|\n",
      "+----+-----+----------+----------+--------+----------+---------+------------+------------+------------------+-------------------------+------------------+-----+-----+---------------------------------+---+\n",
      "|   0|    0|     11593|     11593|   11594|     11594|    11593|       11600|       11600|             11601|                    11605|             11593|11600|11606|                            11650|  0|\n",
      "+----+-----+----------+----------+--------+----------+---------+------------+------------+------------------+-------------------------+------------------+-----+-----+---------------------------------+---+\n",
      "\n",
      "airport to warehouse\n",
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      " |-- city_id: long (nullable = true)\n",
      "\n",
      "Shape: (22757, 10)\n",
      "+-----+-------------+--------------------+------------+---------+-----------+-------------------+------------------+-----+------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|           latitude|         longitude|   id|     city_id|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+-------------------+------------------+-----+------------+\n",
      "| KAVL|large_airport|Asheville Regiona...|        2165|       NA|         US| -82.54180145263672| 35.43619918823242|13638|377957122049|\n",
      "| NC67|small_airport|    Six Oaks Airport|        2015|       NA|         US|           -82.4525|         35.467778|17789|377957122049|\n",
      "| NC95|     heliport|Mission Hospitals...|        2200|       NA|         US|         -82.548501|         35.575298|17818|377957122049|\n",
      "| 3NY2|     heliport|    Astoria Heliport|          15|       NA|         US| -73.91210174560547| 40.78620147705078| 4487|          21|\n",
      "| K20U|small_airport|       Beach Airport|        2756|       NA|         US|-103.98200225830078|46.925201416015625|12839|          48|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+-------------------+------------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Null counts:\n",
      "+-----+----+----+------------+---------+-----------+--------+---------+---+-------+\n",
      "|ident|type|name|elevation_ft|continent|iso_country|latitude|longitude| id|city_id|\n",
      "+-----+----+----+------------+---------+-----------+--------+---------+---+-------+\n",
      "|    0|   0|   0|         239|        0|          0|       0|        0|  0|    102|\n",
      "+-----+----+----+------------+---------+-----------+--------+---------+---+-------+\n",
      "\n",
      "sas to warehouse\n",
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- I94CIT: integer (nullable = true)\n",
      " |-- I94RES: integer (nullable = true)\n",
      " |-- port: string (nullable = true)\n",
      " |-- arrdate: date (nullable = true)\n",
      " |-- arrmode_id: integer (nullable = true)\n",
      " |-- addr_state: string (nullable = true)\n",
      " |-- depdate: date (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- visa_id: integer (nullable = true)\n",
      " |-- match_flag: boolean (nullable = false)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- admission_num: double (nullable = true)\n",
      " |-- flight_num: string (nullable = true)\n",
      " |-- visatype_id: long (nullable = true)\n",
      " |-- airline_id: long (nullable = true)\n",
      " |-- gender_id: long (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      " |-- city_id: long (nullable = true)\n",
      "\n",
      "Shape: (3096313, 22)\n",
      "+-------+----+-----+------+------+----+----------+----------+----------+----------+---+-------+----------+----------+------+---------------+----------+-----------+----------+---------+------------+----------+\n",
      "|  cicid|year|month|I94CIT|I94RES|port|   arrdate|arrmode_id|addr_state|   depdate|age|visa_id|match_flag|birth_year|insnum|  admission_num|flight_num|visatype_id|airline_id|gender_id|          id|   city_id|\n",
      "+-------+----+-----+------+------+----+----------+----------+----------+----------+---+-------+----------+----------+------+---------------+----------+-----------+----------+---------+------------+----------+\n",
      "|2867760|2016|    4|   691|   691| CNA|2016-04-15|         3|      null|2016-04-17| 44|      2|      true|      1972|  null| 8.767308293E10|     01031|          2|      null|        0|171799155582|8589934593|\n",
      "|4691347|2016|    4|   129|   129| CNA|2016-04-25|         3|      null|2016-05-29| 18|      3|      true|      1998|  null| 8.443655563E10|     00121|          3|      null|        0|171799156798|8589934593|\n",
      "|1356812|2016|    4|   111|   111| CNA|2016-04-08|         3|        ME|2016-04-10| 27|      2|      true|      1989|  null|   7.41520185E8|      LAND|          9|      null|        0|171799166805|8589934593|\n",
      "|4035007|2016|    4|   111|   111| CNA|2016-04-22|         3|        ME|2016-04-24|  6|      2|      true|      2010|  null|4.2318202933E10|      LAND|          9|      null|        0|171799166806|8589934593|\n",
      "|4035009|2016|    4|   111|   111| CNA|2016-04-22|         3|        ME|2016-04-24|  2|      2|      true|      2014|  null|4.2318203833E10|      LAND|          9|      null|        0|171799166807|8589934593|\n",
      "+-------+----+-----+------+------+----+----------+----------+----------+----------+---+-------+----------+----------+------+---------------+----------+-----------+----------+---------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Null counts:\n",
      "+-----+----+-----+------+------+----+-------+----------+----------+-------+---+-------+----------+----------+-------+-------------+----------+-----------+----------+---------+---+-------+\n",
      "|cicid|year|month|I94CIT|I94RES|port|arrdate|arrmode_id|addr_state|depdate|age|visa_id|match_flag|birth_year| insnum|admission_num|flight_num|visatype_id|airline_id|gender_id| id|city_id|\n",
      "+-----+----+-----+------+------+----+-------+----------+----------+-------+---+-------+----------+----------+-------+-------------+----------+-----------+----------+---------+---+-------+\n",
      "|    0|   0|    0|     0|     0|   0|      0|       239|    152592| 142457|802|      0|         0|       802|2982605|            0|     19549|          0|     83627|   414269|  0| 100955|\n",
      "+-----+----+-----+------+------+----+-------+----------+----------+-------+---+-------+----------+----------+-------+-------------+----------+-----------+----------+---------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans = uz.Transformer(None, 'warehouse', write=False, verbose=True)\n",
    "trans.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### GET the datasets FROM warehouse\n",
    "\n",
    "- Because the transformed data was never saved to S3 (due to internet connectivity issues, described above), the entire data pipeline is recreated here\n",
    "- In practice, normalized tables would _likely_ be queried directly from normalized tables in S3 for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting: warehouse - None\n",
      "Preparing all datasets for storage in the data warehouse\n",
      "Transforming city to staging as an intermediary step\n",
      "Loading raw city file from Udacity workspace\n",
      "Getting: raw - city\n",
      "Transforming airport to staging as an intermediary step\n",
      "Getting: raw - airport\n",
      "Transforming sas to staging as an intermediary step\n",
      "Getting: raw - sas\n",
      "Creating id columns from full-text columns for faster querying...\n",
      "...creating visatype_id to visatype mapping\n",
      "...creating airline_id to airline mapping\n",
      "...creating gender_id to gender mapping\n",
      "Creating city_id columns...\n",
      "...get cities not represented in cities dimension from SAS and append to city table\n",
      "......sas_unique_locations shape: (280, 2)\n",
      "......Additional locations from SAS: 205\n",
      "\tcity table shape: (801, 15)\n",
      "...get cities not represented in cities dimension from AIRPORT and append to city table\n",
      "......airport_unique_locations shape: (11951, 2)\n",
      "......Additional locations from AIRPORT: 11388\n",
      "\tcity table shape: (12189, 15)\n",
      "Add monotonically increasing city ID to city table\n",
      "Apply city_id to airport\n",
      "Apply city_id to sas\n",
      "Applying full-text maps to SAS from maps.py for readability\n",
      "Applying full-text maps to SAS from ./maps/sas_id_to_fullText_maps.json for readability\n",
      "Apply city_id to city, state map to SAS\n",
      "Apply city_id to city, state map to AIRPORT\n"
     ]
    }
   ],
   "source": [
    "dwh = uz.S3IO(None, 'warehouse', from_raw=True)\n",
    "dwh.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sas has data!\n",
      "All columns in sas have data\n",
      "city has data!\n",
      "All columns in city have data\n",
      "airport has data!\n",
      "All columns in airport have data\n"
     ]
    }
   ],
   "source": [
    "uz.check_has_data(dwh.sas, 'sas')\n",
    "uz.check_no_empty_columns(dwh.sas, 'sas')\n",
    "uz.check_has_data(dwh.city, 'city')\n",
    "uz.check_no_empty_columns(dwh.city, 'city')\n",
    "uz.check_has_data(dwh.airport, 'airport')\n",
    "uz.check_no_empty_columns(dwh.airport, 'airport')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Views from DWH\n",
    "\n",
    "##### SAS DWH Data View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- I94CIT: integer (nullable = true)\n",
      " |-- I94RES: integer (nullable = true)\n",
      " |-- port: string (nullable = true)\n",
      " |-- arrdate: date (nullable = true)\n",
      " |-- arrmode_id: integer (nullable = true)\n",
      " |-- addr_state: string (nullable = true)\n",
      " |-- depdate: date (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- visa_id: integer (nullable = true)\n",
      " |-- match_flag: boolean (nullable = false)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- admission_num: double (nullable = true)\n",
      " |-- flight_num: string (nullable = true)\n",
      " |-- visatype_id: long (nullable = true)\n",
      " |-- airline_id: long (nullable = true)\n",
      " |-- gender_id: long (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      " |-- city_id: long (nullable = true)\n",
      " |-- arrmode: string (nullable = true)\n",
      " |-- visa: string (nullable = true)\n",
      " |-- cit_country: string (nullable = true)\n",
      " |-- res_country: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n",
      "Shape: (3096313, 31)\n",
      "+-------+----+-----+------+------+----+----------+----------+----------+----------+---+-------+----------+----------+------+--------------+----------+-----------+----------+---------+------------+------------+-------+--------+-----------+-----------+--------+-------+------+------+-----+\n",
      "|  cicid|year|month|I94CIT|I94RES|port|   arrdate|arrmode_id|addr_state|   depdate|age|visa_id|match_flag|birth_year|insnum| admission_num|flight_num|visatype_id|airline_id|gender_id|          id|     city_id|arrmode|    visa|cit_country|res_country|visatype|airline|gender|  city|state|\n",
      "+-------+----+-----+------+------+----+----------+----------+----------+----------+---+-------+----------+----------+------+--------------+----------+-----------+----------+---------+------------+------------+-------+--------+-----------+-----------+--------+-------+------+------+-----+\n",
      "|1773994|2016|    4|   718|   243| DEN|2016-04-09|         1|        NJ|2016-04-10| 48|      2|      true|      1968|  null|9.315168233E10|     00012|          2|         3|        0|171798692723|137438953476|    Air|Pleasure|       null|      BURMA|      B2|     CI|     F|Denver|   CO|\n",
      "|3139910|2016|    4|   204|   204| DEN|2016-04-17|         1|        CA|2016-05-22| 56|      2|      true|      1960|  null|9.384389213E10|     00008|          2|         3|        0|171798692905|137438953476|    Air|Pleasure|  INDONESIA|  INDONESIA|      B2|     CI|     F|Denver|   CO|\n",
      "|3379614|2016|    4|   260|   260| DEN|2016-04-18|         1|        CA|2016-05-19| 16|      2|      true|      2000|  null|9.392248173E10|     00004|          2|         3|        0|171798692994|137438953476|    Air|Pleasure|PHILIPPINES|PHILIPPINES|      B2|     CI|     F|Denver|   CO|\n",
      "|2344189|2016|    4|   204|   204| DEN|2016-04-12|         1|        CA|2016-05-02| 55|      2|      true|      1961|  null|9.338082423E10|     00008|          2|         3|        0|171798693026|137438953476|    Air|Pleasure|  INDONESIA|  INDONESIA|      B2|     CI|     F|Denver|   CO|\n",
      "|2558847|2016|    4|   268|   268| DEN|2016-04-13|         1|        CA|2016-06-29| 63|      2|      true|      1953|  null|9.346079983E10|     00006|          2|         3|        0|171798693105|137438953476|    Air|Pleasure|     TAIWAN|     TAIWAN|      B2|     CI|     F|Denver|   CO|\n",
      "+-------+----+-----+------+------+----+----------+----------+----------+----------+---+-------+----------+----------+------+--------------+----------+-----------+----------+---------+------------+------------+-------+--------+-----------+-----------+--------+-------+------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uz.df_overview(dwh.sas, show_nulls=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### City DWH Data View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_full: string (nullable = true)\n",
      " |-- median_age: double (nullable = true)\n",
      " |-- male_pop: integer (nullable = true)\n",
      " |-- female_pop: integer (nullable = true)\n",
      " |-- total_pop: integer (nullable = true)\n",
      " |-- num_veterans: integer (nullable = true)\n",
      " |-- foreign_born: integer (nullable = true)\n",
      " |-- avg_household_size: double (nullable = true)\n",
      " |-- Black or African-American: integer (nullable = true)\n",
      " |-- Hispanic or Latino: integer (nullable = true)\n",
      " |-- White: integer (nullable = true)\n",
      " |-- Asian: integer (nullable = true)\n",
      " |-- American Indian and Alaska Native: integer (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n",
      "Shape: (12189, 16)\n",
      "+-----------+-----+--------------+----------+--------+----------+---------+------------+------------+------------------+-------------------------+------------------+------+-----+---------------------------------+---+\n",
      "|       city|state|    state_full|median_age|male_pop|female_pop|total_pop|num_veterans|foreign_born|avg_household_size|Black or African-American|Hispanic or Latino| White|Asian|American Indian and Alaska Native| id|\n",
      "+-----------+-----+--------------+----------+--------+----------+---------+------------+------------+------------------+-------------------------+------------------+------+-----+---------------------------------+---+\n",
      "|   Gastonia|   NC|North Carolina|      36.9|   35527|     39023|    74550|        3537|        5715|              2.67|                    22179|              6653| 46362| 2788|                              603|  0|\n",
      "|  Henderson|   NV|        Nevada|      42.5|  139412|    146246|   285658|       25045|       35666|              2.55|                    18816|             47154|234301|24931|                             3036|  1|\n",
      "|Yorba Linda|   CA|    California|      45.5|   31960|     36006|    67966|        3171|       15532|               3.0|                     1326|             10599| 49980|17616|                              211|  2|\n",
      "|    Medford|   OR|        Oregon|      38.6|   39606|     40189|    79795|        6632|        6185|              2.65|                     1201|             14294| 75464| 2135|                             1239|  3|\n",
      "|      Kenai|   AK|          null|      null|    null|      null|     null|        null|        null|              null|                     null|              null|  null| null|                             null|  4|\n",
      "+-----------+-----+--------------+----------+--------+----------+---------+------------+------------+------------------+-------------------------+------------------+------+-----+---------------------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uz.df_overview(dwh.city, show_nulls=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Airport DWH Data View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      " |-- city_id: long (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n",
      "Shape: (22757, 12)\n",
      "+-----+-------------+--------------------+------------+---------+-----------+------------------+------------------+-----+-----------+-------------+-----+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|          latitude|         longitude|   id|    city_id|         city|state|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+------------------+------------------+-----+-----------+-------------+-----+\n",
      "| 58FD|small_airport|   Southerly Airport|          78|       NA|         US|-81.54060363769531| 28.01420021057129| 6101|         26|       Dundee|   FL|\n",
      "| 5KY4|small_airport|      Standard Field|         665|       NA|         US|      -87.17639923|       36.80279922| 6388|         29|       Elkton|   KY|\n",
      "| 78WA|small_airport|Center Island Air...|         115|       NA|         US|    -122.832000732|     48.4901008606| 8060|34359738398|Center Island|   WA|\n",
      "| ME16|small_airport|Loring Internatio...|         746|       NA|         US|        -67.885902|         46.950401|16904|68719476787|    Limestone|   ME|\n",
      "| TA43|small_airport|    Anderosa Airpark|         205|       NA|         US|-94.85440063476562|31.047500610351562|19987|68719476798|     Corrigan|   TX|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+------------------+------------------+-----+-----------+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uz.df_overview(dwh.airport, show_nulls=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### SAS Data Dictionary\n",
    "\n",
    "- `id`: long (nullable = false)\n",
    "- `cicid`: integer (nullable = true)\n",
    "- `year`: integer (nullable = true)\n",
    "  - Year of immigration status change\n",
    "- `month`: integer (nullable = true)\n",
    "  - Month of immigration status change\n",
    "- `I94CIT`: integer (nullable = true)\n",
    "  - Country of citizenship code\n",
    "- `I94RES`: integer (nullable = true)\n",
    "  - Country of residence code\n",
    "- `cit_country`: string (nullable = true)\n",
    "  - Country of citizenship full text\n",
    "- `res_country`: string (nullable = true)\n",
    "  - Country of residence full text\n",
    "- `port`: string (nullable = true)\n",
    "  - Port of entry\n",
    "- `arrdate`: date (nullable = true)\n",
    "  - Arrival date\n",
    "- `arrmode`: string (nullable = true)\n",
    "  - Mode of arrival (Land, Sea, Air)\n",
    "- `arrmode_id`: integer (nullable = true)\n",
    "  - `arrmode` ID\n",
    "- `addr_state`: string (nullable = true)\n",
    "  - State in which they live\n",
    "- `depdate`: date (nullable = true)\n",
    "  - Departure date\n",
    "- `age`: integer (nullable = true)\n",
    "  - Age at the time of the record\n",
    "- `birth_year`: integer (nullable = true)\n",
    "  - Year in which person was born\n",
    "- `visa`: string (nullable = true)\n",
    "  - Visa category - Business, Pleasure, Student\n",
    "- `visa_id`: integer (nullable = true)\n",
    "  - `visa` normalized\n",
    "- `match_flag`: boolean (nullable = false)\n",
    "  - Match flag - Match of arrival and departure records\n",
    "- `insnum`: string (nullable = true)\n",
    "  - INS number\n",
    "- `admission_num`: double (nullable = true)\n",
    "  - Admission number \n",
    "- `flight_num`: string (nullable = true)\n",
    "  - Flight number\n",
    "- `visatype`: string (nullable = true)\n",
    "  - Class of admission legally admitting the non-immigrant to temporarily stay in U.S.\n",
    "- `visatype_id`: long (nullable = true)\n",
    "  - Visatype normalized\n",
    "- `airline`: string (nullable = true)\n",
    "  - Airline string code abbreviation\n",
    "- `airline_id`: long (nullable = true)\n",
    "  - `airline` normalized\n",
    "- `gender`: string (nullable = true)\n",
    "  - Gender string code\n",
    "- `gender_id`: long (nullable = true)\n",
    "  - `gender` normalized\n",
    "- `city_id`: long (nullable = true)\n",
    "  - Port city id, joinable on `city.id`\n",
    "- `city`: string (nullable = true)\n",
    "  - Port city full text\n",
    "- `state`: string (nullable = true)\n",
    "  - Port city full text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### City Data Dictionary\n",
    "\n",
    "- `id`: long (nullable = false)\n",
    "- `city`: string (nullable = true)\n",
    "- `state`: string (nullable = true)\n",
    "  - State abbreviation\n",
    "- `state_full`: string (nullable = true)\n",
    "  - State spelled out\n",
    "- `median_age`: double (nullable = true)\n",
    "  - Median age of all residents\n",
    "- `male_pop`: integer (nullable = true)\n",
    "  - Count of males\n",
    "- `female_pop`: integer (nullable = true)\n",
    "  - Count of females\n",
    "- `total_pop`: integer (nullable = true)\n",
    "  - Count of all residents\n",
    "- `num_veterans`: integer (nullable = true)\n",
    "  - Count of veterans\n",
    "- `foreign_born`: integer (nullable = true)\n",
    "  - Count of foreign-born citizens\n",
    "- `avg_household_size`: double (nullable = true)\n",
    "  - Average number of people in a house\n",
    "- `Black or African-American`: integer (nullable = true)\n",
    "  - Count of black/African-Americans\n",
    "- `Hispanic or Latino: integer` (nullable = true)\n",
    "  - Count of hispanic/latinos\n",
    "- `White`: integer (nullable = true)\n",
    "  - Count of white people\n",
    "- `Asian`: integer (nullable = true)\n",
    "  - Count of asians\n",
    "- `American Indian and Alaska Native`: integer (nullable = true)\n",
    "  - Count of Native Americans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Airport Data Dictionary\n",
    "\n",
    "- `id`: long (nullable = false)\n",
    "  - Unique row identifier\n",
    "- `ident`: string (nullable = true)\n",
    "  - Identifier code\n",
    "- `type`: string (nullable = true)\n",
    "  - Airport type (small_airport, heliport, medium_airport, closed, seaplane_base, large_airport, balloonport)\n",
    "- `name`: string (nullable = true)\n",
    "  - Name of airport\n",
    "- `elevation_ft`: integer (nullable = true)\n",
    "  - Elevation Feet\n",
    "- `continent`: string (nullable = true)\n",
    "  - Continent of airport location (filtered to be only NA)\n",
    "- `iso_country`: string (nullable = true)\n",
    "  - Country of location (filtered to be only US)\n",
    "- `latitude`: double (nullable = true)\n",
    "- `longitude`: double (nullable = true)\n",
    "- `city_id`: long (nullable = true)\n",
    "  - City ID, joinable to \n",
    "- `city`: string (nullable = true)\n",
    "  - City full text\n",
    "- `state`: string (nullable = true)\n",
    "  - State two letter abbreviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "  - Spark is a great choice (API simplicity, performance advantages) for analyzing and transforming large datasets that cannot fit into memory\n",
    "  - SAS dataset has over 3M rows\n",
    "  - Data is transformed and saved in S3 where anyone with appropriate permissions can access it\n",
    "* Propose how often the data should be updated and why.\n",
    "  - The immigration data represents one month of immigration transactions, so at minimum, should be updated monthly\n",
    "  - Airports and City information are slower to change, so should be updated, perhaps, quarterly or yearly\n",
    "  - More frequent updates would be necessary, due to user requirements\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "  * The data was increased by 100x.\n",
    "    - Potentially save datasets to AWS Redshift or EMR cluster for better performance and scalability\n",
    "    - Potentially increase the number of Spark workers\n",
    "    - Potentially partition the data in more ways, depending on querying habits\n",
    "    - Potentially normalize the dataset even further to optimize storage\n",
    "    - Potentially incorporate some OLAP cubes for faster BI analysis, depending on users' needs\n",
    "  * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "    - Add an 'append' functionality that takes in new data, applies transformations, maps updates where appropriate, and data quality checks as needed to transform new and append to existing data\n",
    "    - Build an Airflow DAG pipeline(s) that run at the appropriate time of night that apply the 'append' functionality to newly acquired data\n",
    "      - Pipeline would have requisite checks that send alerts/emails if things fail\n",
    "      - Incorporate logging for historical debugging\n",
    "  * The database needed to be accessed by 100+ people.\n",
    "    - Use AWS Redshift for readability performance and grant users credentials for access into the relevant part(s) of the dataset(s)\n",
    "    - Create different views or aggregations to spread out the database and provide users a better experience"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
